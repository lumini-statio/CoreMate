{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "087f10a5-9e18-45e4-8211-2a375ff24214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7f991eb-b380-4c05-8fb5-9125d6b15454",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 50000\n",
    "sequence_len = 90\n",
    "batch_size = 64\n",
    "embed_dim = 256\n",
    "num_heads = 4\n",
    "ff_dim = 512\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0a24d28-ddd6-4fcf-997a-fa951ed8b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv('data/general.csv', quote_char='\"').select(['question', 'answer'])\n",
    "df2 = pl.read_csv('data/reddit.csv', ignore_errors=True).select(['question', 'answer'])\n",
    "df3 = pl.read_csv('data/suicidio.csv', ignore_errors=True).select(['question', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddc24530-e5b6-4095-a5aa-07914905ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pl.concat([df, df2, df3], how=\"vertical\").drop_nulls().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33ae40a3-cd6f-48ca-a70e-132c63079894",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = df_total[\"question\"].cast(str).to_list()\n",
    "answers = [f\"[START] {a.strip()} [END]\" for a in df_total[\"answer\"].cast(str).to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31c2b1d2-0ac9-4c10-90b5-3804e0bfa882",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vectorizer = layers.TextVectorization(\n",
    "    max_tokens=max_vocab_size, output_mode=\"int\", output_sequence_length=sequence_len\n",
    ")\n",
    "answer_vectorizer = layers.TextVectorization(\n",
    "    max_tokens=max_vocab_size, output_mode=\"int\", output_sequence_length=sequence_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bace0223-1736-4a0d-8d80-837233770368",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vectorizer.adapt(questions)\n",
    "answer_vectorizer.adapt(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0db52e2-6a3e-43ee-b8a2-0f578f44c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_tensor = question_vectorizer(questions)\n",
    "answers_tensor = answer_vectorizer(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "341dff7f-5d25-44f5-99a0-d2d71d07c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = questions_tensor\n",
    "decoder_input = answers_tensor[:, :-1]\n",
    "decoder_target = answers_tensor[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e266379-1dde-4d9b-96c0-ceac828a884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = encoder_input.shape[0]\n",
    "val_split = int(data_size * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0484f73-0777-4f7d-a322-d9135f39d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(\n",
    "    ((encoder_input[val_split:], decoder_input[val_split:]), decoder_target[val_split:])\n",
    ")\n",
    "val_data = tf.data.Dataset.from_tensor_slices(\n",
    "    ((encoder_input[:val_split], decoder_input[:val_split]), decoder_target[:val_split])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87a07ab2-6d49-499d-938e-33e717576167",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.shuffle(1024).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_data = val_data.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea559160-1201-4386-85d1-46b075239ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "    inputs = layers.Input(shape=(None,))\n",
    "    x = layers.Embedding(max_vocab_size, embed_dim)(inputs)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(x, x)\n",
    "    x = layers.Add()([x, attn])\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    ffn = keras.Sequential([\n",
    "        layers.Dense(ff_dim, activation=\"relu\"),\n",
    "        layers.Dense(embed_dim),\n",
    "    ])\n",
    "    x = layers.Add()([x, ffn(x)])\n",
    "    return keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "347b1b39-bbee-4195-b9b8-0174f93203f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_decoder(embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "    enc_inputs = layers.Input(shape=(None, embed_dim))\n",
    "    dec_inputs = layers.Input(shape=(None,))\n",
    "    x = layers.Embedding(max_vocab_size, embed_dim)(dec_inputs)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    attn1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(x, x)\n",
    "    x = layers.Add()([x, attn1])\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    attn2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(x, enc_inputs)\n",
    "    x = layers.Add()([x, attn2])\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    ffn = keras.Sequential([\n",
    "        layers.Dense(ff_dim, activation=\"relu\"),\n",
    "        layers.Dense(embed_dim),\n",
    "    ])\n",
    "    x = layers.Add()([x, ffn(x)])\n",
    "    outputs = layers.Dense(max_vocab_size, activation=\"softmax\")(x)\n",
    "    return keras.Model([enc_inputs, dec_inputs], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2638a02-a925-4040-ab06-a27f2f91a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = transformer_encoder(embed_dim, num_heads, ff_dim, dropout=dropout_rate)\n",
    "decoder = transformer_decoder(embed_dim, num_heads, ff_dim, dropout=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a66eba3-10cd-4047-aba1-0f6c2f4bafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inputs = layers.Input(shape=(None,))\n",
    "dec_inputs = layers.Input(shape=(None,))\n",
    "enc_outputs = encoder(enc_inputs)\n",
    "dec_outputs = decoder([enc_outputs, dec_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35763bba-8b2a-4fa5-9850-9440afd0d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model([enc_inputs, dec_inputs], dec_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50186613-3dbf-48a3-aae4-d8ef60efa741",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c1b58d1-944d-400a-a5a9-fe4bf0dd4732",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5ce56-fc0d-4e33-8fa8-be645d753d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data, validation_data=val_data, epochs=10, callbacks=callbacks)\n",
    "model.save('CoreMate_v1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (coremate)",
   "language": "python",
   "name": "coremate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
